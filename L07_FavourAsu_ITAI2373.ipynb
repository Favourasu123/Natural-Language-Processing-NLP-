{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this first cell we import python libraries numpy for linear algebra,\n",
        "pandas to allow us work with data, and os to enable us interact with\n",
        "our machines operating system"
      ],
      "metadata": {
        "id": "xmPco7fL2HcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-08-29T09:10:35.004292Z",
          "iopub.execute_input": "2021-08-29T09:10:35.004802Z",
          "iopub.status.idle": "2021-08-29T09:10:35.015497Z",
          "shell.execute_reply.started": "2021-08-29T09:10:35.004680Z",
          "shell.execute_reply": "2021-08-29T09:10:35.014731Z"
        },
        "trusted": true,
        "id": "KRVvfQ8n15iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this dataset is so big, we only want to read the first 8 million rows"
      ],
      "metadata": {
        "id": "PWFRlcM62oY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# full dataset not taking load\n",
        "df = pd.read_csv(\"/kaggle/input/en-fr-translation-dataset/en-fr.csv\", nrows=8000000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T09:10:35.017339Z",
          "iopub.execute_input": "2021-08-29T09:10:35.017716Z",
          "iopub.status.idle": "2021-08-29T09:11:22.244340Z",
          "shell.execute_reply.started": "2021-08-29T09:10:35.017677Z",
          "shell.execute_reply": "2021-08-29T09:11:22.243424Z"
        },
        "trusted": true,
        "id": "39K1wxJi15iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary packages for natural language processing tasks using PyTorch\n",
        "And determines whether to use a GPU (\"cuda\") or CPU for computations, based on availability."
      ],
      "metadata": {
        "id": "2Q3f-0Wo29hO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# device type \"cuda\" or \"cpu\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T09:11:22.246179Z",
          "iopub.execute_input": "2021-08-29T09:11:22.246567Z",
          "iopub.status.idle": "2021-08-29T09:11:22.959568Z",
          "shell.execute_reply.started": "2021-08-29T09:11:22.246525Z",
          "shell.execute_reply": "2021-08-29T09:11:22.958721Z"
        },
        "trusted": true,
        "id": "wc9bvSMb15iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a language class that represents a vocabulary for natural language processing tasks. The class contains methods to add sentences and words to the vocabulary while keeping track of their occurrences. Additionally, there are functions to convert Unicode characters to ASCII and normalize strings by lowercasing, trimming, and removing non-letter characters, preparing text data for further processing.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SBODneaA3WHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {} # word → index (word2index)\n",
        "        self.word2count = {} # index → word (index2word)\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2 # count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    '''\n",
        "    For each character, there are two normal forms:\n",
        "    normal form C and normal form D.\n",
        "    Normal form D (NFD) is also known as canonical decomposition, and translates each character into its decomposed form.\n",
        "    Normal form C (NFC) first applies a canonical decomposition, then composes pre-combined characters again.\n",
        "    '''\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T09:11:22.963146Z",
          "iopub.execute_input": "2021-08-29T09:11:22.963405Z",
          "iopub.status.idle": "2021-08-29T09:11:22.972388Z",
          "shell.execute_reply.started": "2021-08-29T09:11:22.963379Z",
          "shell.execute_reply": "2021-08-29T09:11:22.971602Z"
        },
        "trusted": true,
        "id": "HoKCVN3J15iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting the maximum length of sequences to 30 tokens and defining the size of the hidden state for the neural network model to be 256."
      ],
      "metadata": {
        "id": "MIcnwY3X3rKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 30 # max 10 words including ending punctuation\n",
        "hidden_size = 256"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T09:11:22.973534Z",
          "iopub.execute_input": "2021-08-29T09:11:22.974034Z",
          "iopub.status.idle": "2021-08-29T09:11:22.992239Z",
          "shell.execute_reply.started": "2021-08-29T09:11:22.973995Z",
          "shell.execute_reply": "2021-08-29T09:11:22.991178Z"
        },
        "trusted": true,
        "id": "wDncq7cR15iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define functions to read and preprocess language pairs for translation tasks. Prepare the data by normalizing strings, creating pairs of sentences, and filtering out pairs that exceed a maximum length or do not start with specified English prefixes."
      ],
      "metadata": {
        "id": "TDP2guIh4BJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readLang(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "    # split into two lines\n",
        "    lines = df.values.tolist()\n",
        "    # select everyline into pairs and normalize\n",
        "    pairs = [\n",
        "        [normalizeString(str(s)) for s in l] for l in lines\n",
        "    ]\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "# filtering to sentences that translate to the form “I am” or “He is” etc.\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T09:11:22.993706Z",
          "iopub.execute_input": "2021-08-29T09:11:22.994176Z",
          "iopub.status.idle": "2021-08-29T09:11:23.004074Z",
          "shell.execute_reply.started": "2021-08-29T09:11:22.994130Z",
          "shell.execute_reply": "2021-08-29T09:11:23.002933Z"
        },
        "trusted": true,
        "id": "7KqN34YD15ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The full process for preparing the data is:**\n",
        "\n",
        "* Read text file and split into lines, split lines into pairs\n",
        "* Normalize text, filter by length and content\n",
        "* Make word lists from sentences in pairs"
      ],
      "metadata": {
        "id": "9RJmP7dT15ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLang(lang1, lang2, reverse)\n",
        "    print(f\"Read sentence pairs: {len(pairs)}\")\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(f\"Trimmed to sentence pairs: {len(pairs)}\")\n",
        "    print(f\"COUNTING WORDS...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted Words...\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData(df.columns.tolist()[0], df.columns.tolist()[1], True)\n",
        "print(random.choice(pairs)) # random choice of pairs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T09:11:23.005503Z",
          "iopub.execute_input": "2021-08-29T09:11:23.006075Z",
          "iopub.status.idle": "2021-08-29T09:31:14.395374Z",
          "shell.execute_reply.started": "2021-08-29T09:11:23.006029Z",
          "shell.execute_reply": "2021-08-29T09:31:14.394497Z"
        },
        "trusted": true,
        "id": "HMgHXX2X15il",
        "outputId": "226fc868-c215-4789-c0e1-a1a970e2da03"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Reading lines...\nRead sentence pairs: 8000000\nTrimmed to sentence pairs: 16663\nCOUNTING WORDS...\nCounted Words...\nfr 18781\nen 14262\n['vous etes l expert !', 'you re the expert !']\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seq2Seq Model\n",
        "\n",
        "## A Sequence to Sequence network, or seq2seq network, or Encoder Decoder network, is a model consisting of two RNNs called the encoder and decoder. The encoder reads an input sequence and outputs a single vector, and the decoder reads that vector to produce an output sequence."
      ],
      "metadata": {
        "id": "xql7Op9y15ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Encoder\n",
        "## The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word.\n",
        "![](https://pytorch.org/tutorials/_images/encoder-network.png)\n",
        "\n",
        "# The Decoder\n",
        "## In the simplest seq2seq decoder we use only last output of the encoder. This last output is sometimes called the context vector as it encodes context from the entire sequence. This context vector is used as the initial hidden state of the decoder.\n",
        "## At every step of decoding, the decoder is given an input token and hidden state. The initial input token is the start-of-string SOS token, and the first hidden state is the context vector (the encoder’s last hidden state).\n",
        "![](https://pytorch.org/tutorials/_images/decoder-network.png)"
      ],
      "metadata": {
        "id": "9MvN7XqK15iq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EncoderRNN: This class defines the encoder component of a sequence-to-sequence model. It embeds input sequences into fixed-size representations using an embedding layer and then passes them through a GRU (Gated Recurrent Unit) to produce hidden states.\n",
        "\n",
        "DecoderRNN: This class represents the decoder component of a sequence-to-sequence model. It takes the hidden states produced by the encoder and generates output sequences. It utilizes an embedding layer followed by a GRU layer to process input tokens and produce output tokens, applying a softmax activation to generate the probability distribution over the output vocabulary."
      ],
      "metadata": {
        "id": "2IelaEvQ5p20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedding = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedding\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    \"\"\"docstring for DecoderRNN\"\"\"\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T09:31:14.397856Z",
          "iopub.execute_input": "2021-08-29T09:31:14.398238Z",
          "iopub.status.idle": "2021-08-29T09:31:14.410438Z",
          "shell.execute_reply.started": "2021-08-29T09:31:14.398200Z",
          "shell.execute_reply": "2021-08-29T09:31:14.409397Z"
        },
        "trusted": true,
        "id": "IYduWEIw15ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting sentences into tensors. indexesFromSentence maps each word in a sentence to its corresponding index in the language vocabulary, while tensorFromSentence and tensorFromPair generate PyTorch tensors from sentences and pairs of sentences, respectively, including an end-of-sentence token.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LA-zDtOC5wu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T09:31:14.412271Z",
          "iopub.execute_input": "2021-08-29T09:31:14.412630Z",
          "iopub.status.idle": "2021-08-29T09:31:14.428784Z",
          "shell.execute_reply.started": "2021-08-29T09:31:14.412593Z",
          "shell.execute_reply": "2021-08-29T09:31:14.428020Z"
        },
        "trusted": true,
        "id": "6zhZHCJ115iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensuring each tensor includes an end-of-sentence token (EOS_token) to mark the end of the sequence."
      ],
      "metadata": {
        "id": "cIRV6EU36Fh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "# Preparing Training Data\n",
        "# To train, for each pair we will need an input tensor (indexes of the words in the input sentence) and target tensor (indexes of the words in the target sentence).\n",
        "# While creating these vectors we will append the EOS token to both sequences.\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T09:31:14.430284Z",
          "iopub.execute_input": "2021-08-29T09:31:14.430914Z",
          "iopub.status.idle": "2021-08-29T09:31:14.438648Z",
          "shell.execute_reply.started": "2021-08-29T09:31:14.430870Z",
          "shell.execute_reply": "2021-08-29T09:31:14.437866Z"
        },
        "trusted": true,
        "id": "b1bQSTf015i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a training function for a sequence-to-sequence model, employing teacher forcing with a given ratio."
      ],
      "metadata": {
        "id": "Ygq27jNJ6YEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden\n",
        "        )\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden\n",
        "            )\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di] # Teacher forcing\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden\n",
        "            )\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach() # detach from history as input\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T09:31:14.440047Z",
          "iopub.execute_input": "2021-08-29T09:31:14.440566Z",
          "iopub.status.idle": "2021-08-29T09:31:14.452949Z",
          "shell.execute_reply.started": "2021-08-29T09:31:14.440528Z",
          "shell.execute_reply": "2021-08-29T09:31:14.451713Z"
        },
        "trusted": true,
        "id": "2krcBYKN15i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Includes utility functions to convert elapsed time into a readable format and estimate the remaining time based on the progress percentage. The asMinutes function converts seconds into minutes and seconds, while timeSince calculates the elapsed time and remaining time based on a given starting time and progress percentage."
      ],
      "metadata": {
        "id": "9hyCNj756sbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(s))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T09:31:14.454329Z",
          "iopub.execute_input": "2021-08-29T09:31:14.454808Z",
          "iopub.status.idle": "2021-08-29T09:31:14.465749Z",
          "shell.execute_reply.started": "2021-08-29T09:31:14.454772Z",
          "shell.execute_reply": "2021-08-29T09:31:14.464806Z"
        },
        "trusted": true,
        "id": "YggoofEF15i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The whole training process looks like this:\n",
        "\n",
        "* Start a timer\n",
        "* Initialize optimizers and criterion\n",
        "* Create set of training pairs\n",
        "* Start empty losses array for plotting"
      ],
      "metadata": {
        "id": "80sDBqeP15i8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def showplot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T09:31:14.467236Z",
          "iopub.execute_input": "2021-08-29T09:31:14.467689Z",
          "iopub.status.idle": "2021-08-29T09:31:14.478625Z",
          "shell.execute_reply.started": "2021-08-29T09:31:14.467653Z",
          "shell.execute_reply": "2021-08-29T09:31:14.477779Z"
        },
        "trusted": true,
        "id": "4uWduG3g15i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines a function to train encoder-decoder models iteratively, logging and plotting the training loss. It iterates through training pairs, computes the loss, and updates model parameters using SGD optimization, while also printing and plotting the average loss at specified intervals."
      ],
      "metadata": {
        "id": "srszkJ4q66lB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0 # Reset every print_every\n",
        "    plot_loss_total = 0 # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    training_pairs = [tensorFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(\n",
        "            input_tensor, target_tensor,\n",
        "            encoder, decoder,\n",
        "            encoder_optimizer, decoder_optimizer,\n",
        "            criterion\n",
        "        )\n",
        "\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "    showplot(plot_losses)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T09:31:14.479836Z",
          "iopub.execute_input": "2021-08-29T09:31:14.480251Z",
          "iopub.status.idle": "2021-08-29T09:31:14.492890Z",
          "shell.execute_reply.started": "2021-08-29T09:31:14.480211Z",
          "shell.execute_reply": "2021-08-29T09:31:14.491819Z"
        },
        "trusted": true,
        "id": "ziM-DbnV15i9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation is mostly the same as training, but there are no targets so we simply feed the decoder’s predictions back to itself for each step. Every time it predicts a word we add it to the output string, and if it predicts the EOS token we stop there."
      ],
      "metadata": {
        "id": "n5CrJj8o15i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words\n",
        "\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "trainIters(encoder1, decoder1, 75000, print_every=5000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T09:31:14.494323Z",
          "iopub.execute_input": "2021-08-29T09:31:14.494703Z",
          "iopub.status.idle": "2021-08-29T10:12:42.895744Z",
          "shell.execute_reply.started": "2021-08-29T09:31:14.494663Z",
          "shell.execute_reply": "2021-08-29T10:12:42.894881Z"
        },
        "trusted": true,
        "id": "swovgJL415i_",
        "outputId": "15c39e8f-41d3-4cd3-eedf-d57a7aa79d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "2m 44s (- 2m 44s) (5000 6%) 4.7117\n5m 23s (- 5m 23s) (10000 13%) 4.4414\n8m 9s (- 8m 9s) (15000 20%) 4.4669\n10m 54s (- 10m 54s) (20000 26%) 4.3943\n13m 40s (- 13m 40s) (25000 33%) 4.2983\n16m 26s (- 16m 26s) (30000 40%) 4.2312\n19m 12s (- 19m 12s) (35000 46%) 4.1375\n21m 58s (- 21m 58s) (40000 53%) 4.0749\n24m 44s (- 24m 44s) (45000 60%) 3.9840\n27m 32s (- 27m 32s) (50000 66%) 3.9153\n30m 17s (- 30m 17s) (55000 73%) 3.8458\n33m 4s (- 33m 4s) (60000 80%) 3.8032\n35m 50s (- 35m 50s) (65000 86%) 3.7357\n38m 38s (- 38m 38s) (70000 93%) 3.6980\n41m 25s (- 41m 25s) (75000 100%) 3.6355\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function randomly selects pairs from the dataset, prints the input and target sentences, then evaluates the model's prediction for the input sentence and prints the output, repeating this process for a specified number of iterations."
      ],
      "metadata": {
        "id": "Qj_U3Wfo7IXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')\n",
        "evaluateRandomly(encoder1, decoder1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T10:12:42.897172Z",
          "iopub.execute_input": "2021-08-29T10:12:42.897521Z",
          "iopub.status.idle": "2021-08-29T10:12:43.044777Z",
          "shell.execute_reply.started": "2021-08-29T10:12:42.897483Z",
          "shell.execute_reply": "2021-08-29T10:12:43.043872Z"
        },
        "trusted": true,
        "id": "n1xtWZtL15jB",
        "outputId": "113b8abd-4ee0-495a-c706-a2597f278c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "> en outre il jouit d une vaste reputation en tant que communicateur sur les questions complexes de politique publique .\n= he is also widely regarded as a gifted communicator on complex public policy questions .\n< he is also a to a of and and as as and as . and . . <EOS>\n\n> ils sont apres tout des proprietaires de droits et sont interesses a encourager le respect des regles .\n= they are rights owners after all and are interested in encouraging respect for the rules .\n< they are designed to the and and and and are rights . <EOS>\n\n> je suis heureuse de vous annoncer que le ministere du patrimoine canadien appuiera la conference inaugurale du reseau des villes creatives .\n= i am pleased to tell you that canadian heritage will support the founding conference of the creative cities network .\n< i am pleased to present the canadian you the to the the the the . <EOS>\n\n> tout le monde aime travailler avec lui et il arrive a interesser tout le monde . \n= he s somebody that everyone likes to work with and is able to get everyone interested . \n< he is always he to he and to to and and and he to to the and to  <EOS>\n\n> il est desormais secretaire d etat amerique latine et afrique francophonie .\n= he is now secretary of state latin america and africa francophonie .\n< he is now the secretary of the american and of the the and . <EOS>\n\n> je constate une baisse dans leur estime de soi .\n= i m noticing a lowering in their self esteem .\n< i m still from a i i am from i <EOS>\n\n> j ai le plaisir d annoncer que le canada va lancer un nouveau programme de main d uvre pour les ameriques qui soutiendra la colombie .\n= i am pleased to announce that canada will launch a new labour program for the americas that will include support for colombia .\n< i m pleased to announce that that canada will continue to be a program for a new program . <EOS>\n\n> l evaluation est faite par la commission de la fonction publique qui peut deleguer ce pouvoir aux organisations .\n= they are assessed by public service commission which can delegate this power to organizations .\n< they are available by the commission of the commission commission by the commission . <EOS>\n\n> de tels organismes vous font connaitre differentes strategies financieres a adopter pour eviter d eventuelles difficultes .\n= they are there to help you with financial strategies to avoid trouble in the future .\n< you are looking to make the to and and and and <EOS>\n\n> ils font aussi un effort pour reduire la tension dans d autres secteurs du systeme de sante tels que dans les salles d urgence .\n= they are also making efforts to relieve pressures found elsewhere in the health system such as emergency rooms .\n< they are also to to of health health such as as as as as . <EOS>\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Takes an input text, evaluates it using the encoder-decoder model, and returns the translated output sentence. The translated output is obtained by joining the predicted words from the model's evaluation.\n"
      ],
      "metadata": {
        "id": "PGGCp3vw7RU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "def translateText(input_text):\n",
        "    output_words = evaluate(\n",
        "        encoder1, decoder1, normalizeString(input_text)\n",
        "    )\n",
        "    output_sentence = ' '.join(output_words)\n",
        "    return f\"Output Sentence: {output_sentence}\"\n",
        "\n",
        "translateText(input_text=input(\"Type sentence: \"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-29T10:15:35.528798Z",
          "iopub.execute_input": "2021-08-29T10:15:35.529175Z",
          "iopub.status.idle": "2021-08-29T10:15:40.713433Z",
          "shell.execute_reply.started": "2021-08-29T10:15:35.529134Z",
          "shell.execute_reply": "2021-08-29T10:15:40.712672Z"
        },
        "trusted": true,
        "id": "Un8i9rrI15jE",
        "outputId": "f507377c-14bc-497a-9a44-d3ab6c064485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Type sentence:  ils font aussi un effort pour reduire la tension dans d autres secteurs\n"
        },
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'Output Sentence: they are also a in a of the in the . <EOS>'"
          },
          "metadata": {}
        }
      ]
    }
  ]
}