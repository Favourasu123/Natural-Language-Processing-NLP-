{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[link text](https://)Write a summary on how the word2vec and glove processes takes place in LLM?\n",
        "Use this website:\n",
        "\n",
        "https://medium.com/bright-ml/glove-embedding-for-sentence-dc49936d24a7\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C_ACSe-9Op1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The article discusses GloVe embedding for sentences. It explains that GloVe is a log-bilinear model that uses co-occurrence of words in a corpus to give words meaning. Word2Vec and GloVe are two prominent techniques used in language model architectures for natural language processing (NLP).\n",
        "\n",
        "Word2Vec is an embedding technique that represents words as continuous vectors in a high-dimensional space. It employs two primary training algorithms: Continuous Bag of Words (CBOW) and Skip-gram. In CBOW, the model predicts a target word based on its context, while Skip-gram predicts context words given a target word. These models leverage neural networks trained on large text corpora to learn vector representations. Once trained, Word2Vec assigns each word a unique vector, capturing semantic relationships effectively. However, it may struggle with rare words and ignores word order.\n",
        "\n",
        "On the other hand, GloVe (Global Vectors for Word Representation) utilizes global word-word co-occurrence statistics to embed words based on their collective context in a corpus. It constructs a word-context matrix to represent the likelihood of words appearing together, then performs matrix factorization to yield refined vector representations for each word. GloVe efficiently captures global statistics of the corpus and is effective in representing semantic and syntactic relationships. However, it requires more memory for storing co-occurrence matrices and may be less effective with very small corpora.\n",
        "\n",
        "These embedding techniques play crucial roles in NLP tasks, offering different advantages and being suitable for diverse datasets. FastText, another advanced embedding technique, extends Word2Vec by incorporating subword information, making it highly effective for morphologically rich languages and handling out-of-vocabulary words. When choosing an embedding model, factors such as semantic relationships, dataset size, and language morphology need to be considered to ensure optimal performance in NLP applications.\n",
        "\n"
      ],
      "metadata": {
        "id": "ME0yLV2YXkxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change input data to do the same analysis on the code provided in below link:**\n",
        "\n",
        "https://medium.com/bright-ml/glove-embedding-for-sentence-dc49936d24a7"
      ],
      "metadata": {
        "id": "RAtmYYg3O8Xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing libraries for word2vec assignment\n",
        "import nltk\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "LZzN3cK8PG25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa8c9ae3-038e-44de-90d2-24e61ed87752"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Toy dataset\n",
        "sentences = [\"I love natural language processing.\",\n",
        "             \"Word embeddings are powerful.\"]"
      ],
      "metadata": {
        "id": "KYyNf8tBYoZ3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize sentences\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "print(tokenized_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFNrc7PkYodb",
        "outputId": "faa9526c-dff1-4e3a-dda8-b2d10f7fb9d1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['i', 'love', 'natural', 'language', 'processing', '.'], ['wor', 'embeddings', 'are', 'powerful', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)"
      ],
      "metadata": {
        "id": "KFvW59xVYogN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_embeddings = model.wv\n",
        "print(word_embeddings['i'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afqVmSzwZSb4",
        "outputId": "7152c2ea-3343-46ef-ba3d-e1e2fbd91706"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00515624 -0.00666834 -0.00777684  0.00831073 -0.00198234 -0.00685496\n",
            " -0.00415439  0.00514413 -0.00286914 -0.00374966  0.00162143 -0.00277629\n",
            " -0.00158436  0.00107449 -0.00297794  0.00851928  0.00391094 -0.00995886\n",
            "  0.0062596  -0.00675425  0.00076943  0.00440423 -0.00510337 -0.00211067\n",
            "  0.00809548 -0.00424379 -0.00763626  0.00925791 -0.0021555  -0.00471943\n",
            "  0.0085708   0.00428334  0.00432484  0.00928451 -0.00845308  0.00525532\n",
            "  0.00203935  0.00418828  0.0016979   0.00446413  0.00448629  0.00610452\n",
            " -0.0032021  -0.00457573 -0.00042652  0.00253373 -0.00326317  0.00605772\n",
            "  0.00415413  0.00776459  0.00256927  0.00811668 -0.00138721  0.00807793\n",
            "  0.00371702 -0.00804732 -0.00393361 -0.00247188  0.00489304 -0.00087216\n",
            " -0.00283091  0.00783371  0.0093229  -0.00161493 -0.00515925 -0.00470176\n",
            " -0.00484605 -0.00960283  0.00137202 -0.00422492  0.00252671  0.00561448\n",
            " -0.00406591 -0.00959658  0.0015467  -0.00670012  0.00249517 -0.00378063\n",
            "  0.00707842  0.00064022  0.00356094 -0.00273913 -0.00171055  0.00765279\n",
            "  0.00140768 -0.00585045 -0.0078345   0.00123269  0.00645463  0.00555635\n",
            " -0.00897705  0.00859216  0.00404698  0.00746961  0.00974633 -0.00728958\n",
            " -0.00903996  0.005836    0.00939121  0.00350693]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "HrDU6qv4atYu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Toy dataset\n",
        "sentences = [\"FastText embeddings handle subword information.\",\n",
        "             \"It is effective for various languages.\"]\n",
        "# Tokenize sentences"
      ],
      "metadata": {
        "id": "03YrABnQathl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize sentences\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]"
      ],
      "metadata": {
        "id": "Q7H2O2dKcQjj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train FastText model\n",
        "model = FastText(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)"
      ],
      "metadata": {
        "id": "0Hh_3J6AcQmW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access embeddings\n",
        "word_embeddings = model.wv\n",
        "print(word_embeddings['subword'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdYX8aD9cQoz",
        "outputId": "c877cfc2-09ea-49ff-e13b-ff29e2f3451d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.2919701e-03 -1.0602611e-04 -1.1323356e-03  1.6584302e-03\n",
            " -5.7117449e-04 -2.9840841e-04 -4.3193492e-04 -3.1250282e-04\n",
            " -1.9898350e-04  9.4852143e-04  1.6994212e-03 -1.8581563e-04\n",
            " -8.1228669e-04 -1.5968895e-03 -1.3839703e-03 -6.3576088e-05\n",
            " -5.7436171e-04 -1.1720147e-03  7.4763177e-04 -2.1684753e-05\n",
            "  4.5981101e-04 -1.7291495e-03 -4.4365969e-04  4.0478929e-04\n",
            "  1.2072949e-04  6.4071972e-04 -1.0785459e-03  1.3050955e-03\n",
            "  3.5044085e-04 -1.8284899e-04 -1.5951110e-04 -1.0465594e-03\n",
            " -1.5170674e-04 -5.7858619e-04 -1.8307484e-03  1.0248278e-03\n",
            "  6.9344341e-04  1.6159177e-03 -8.4400486e-04  8.9535897e-04\n",
            " -1.3508157e-04  2.3538095e-03 -3.7109022e-04 -2.8064058e-04\n",
            "  2.6269807e-04 -2.8326022e-04 -7.7332847e-04  1.8949938e-03\n",
            "  2.1798143e-03 -4.4569728e-04 -6.4175081e-04  1.4240020e-04\n",
            "  2.5182988e-03 -1.5666584e-03  1.3954224e-04 -6.9046958e-04\n",
            "  5.8793183e-04 -1.4282564e-03  2.1278318e-04 -2.2993281e-03\n",
            " -4.3249400e-03 -1.6397990e-03  1.3989839e-03 -1.3229308e-03\n",
            "  2.0258871e-03 -2.9663873e-04 -1.7821314e-03 -1.9624084e-04\n",
            " -3.8101443e-04  1.2712786e-03 -4.8752314e-05 -1.6701949e-03\n",
            " -4.0860524e-04 -2.3929863e-03 -1.1424356e-03 -8.1383681e-04\n",
            " -4.9799628e-04 -1.4722025e-03 -1.8545202e-03 -4.9134775e-04\n",
            "  2.1096619e-03 -3.5232501e-05  3.5016984e-03  1.4268994e-04\n",
            "  7.3083641e-04 -1.6456110e-03 -1.8567833e-03 -8.2786253e-04\n",
            "  2.2351660e-04  2.1772250e-03  1.3073307e-03  7.8967125e-05\n",
            "  2.6948133e-04 -2.0950858e-03  2.1080931e-03  4.0393372e-04\n",
            "  1.4223440e-03  6.8460318e-04  2.4361876e-03  5.3560670e-04]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "Nv3W8hoCcQrT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example sentence\n",
        "sentences = [['this', 'is', 'that', 'a', 'ball', 'you', 'me', 'myself']]"
      ],
      "metadata": {
        "id": "6zNZ32h6eP5q"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(sentences, min_count=1, window=2, sg=1)"
      ],
      "metadata": {
        "id": "od8WWasNeP8A"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = model.wv"
      ],
      "metadata": {
        "id": "OXeRZJfoetNR"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity = word_vectors.similarity('this', 'that')\n",
        "print(f\"Similarity between 'this' and 'that': {similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y5jO596etQB",
        "outputId": "d87eef9d-c8fb-4cf3-a38a-b35d725f9424"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between 'this' and 'that': -0.05774581432342529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_similar = word_vectors.most_similar('this')\n",
        "print(f\"Most similar words to 'this': {most_similar}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uJ8iAKdetS9",
        "outputId": "51859817-54e7-4678-8c1f-d32b36e264fe"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most similar words to 'this': [('myself', 0.09291722625494003), ('is', 0.00484249135479331), ('you', -0.0027540253940969706), ('ball', -0.013679751195013523), ('a', -0.028491031378507614), ('that', -0.05774581804871559), ('me', -0.11555545777082443)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cu46lMY6etVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-cQqKfazetYE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}